# MLX LLM Server Configuration Example
# Copy this file to .env and adjust the values

# Server Configuration
SERVER_HOST=0.0.0.0
SERVER_PORT=9123  # Dev mode default. Production uses 443 with SSL
SERVER_WORKERS=1  # Keep at 1 for MLX

# SSL/TLS Configuration (optional - for HTTPS)
# Leave empty for HTTP development server
SSL_CERT=
SSL_KEY=

# Domain Configuration (optional - for production)
PRIMARY_DOMAIN=localhost
TAILSCALE_DOMAIN=
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:9123","http://127.0.0.1:9123"]

# Model Configuration
# You can use local paths or HuggingFace model IDs
MODELS_DIR=./models
DEFAULT_MODEL=LibraxisAI/Qwen3-14b-MLX-Q5  # Premium quality 14B model
MAX_MODEL_MEMORY_GB=32  # Adjust based on your system RAM (min 16GB for Qwen3-14b)

# API Configuration
API_PREFIX=/api/v1
MAX_TOKENS_DEFAULT=2048
MAX_TOKENS_LIMIT=32768

# Redis Configuration (optional - for session persistence)
# Leave as-is for in-memory sessions, or set up Redis for persistence
REDIS_URL=redis://localhost:6379/0
SESSION_TTL_HOURS=24

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# Authentication
ENABLE_AUTH=true
# Generate keys with: ./generate_api_keys.py
# Format: ["key1", "key2"] for JSON array
API_KEYS=["your-api-key-here"]
# JWT secret will be auto-generated if not provided
JWT_SECRET=
JWT_ALGORITHM=HS256

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090

# Advanced Configuration (usually not needed)
# Voice API Configuration (for future voice processing split)
VOICE_API_HOST=
VOICE_SERVICES=[]